---
title: "final project"
author: "Zheer Wang"
date: "2024-04-27"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(GGally)
library(readxl)
library(dplyr)
library(tidyverse)
library(dplyr)
library(tidyverse)
library(car)
library(corrplot)
library(reshape2)

survey = read.csv("/Users/ziqixu/Downloads/stat425/Survey.csv")
survey

```

```{r}
library(tidyverse)
survey %>% count(Fatigue.level)
survey %>% count(Noise.level)
survey %>% count(Primary.hand)
survey %>% count(Visual.acuity)
survey %>% count(Temp.level)
survey %>% count(Cautious.level)
survey %>% count(Input.device)
survey %>% count(Age)
survey %>% count(Device.OS)

```

```{r}
### deal with Input.device
survey <- survey %>%
mutate(Inputdevice.new = case_when(
Input.device %in% c("Game controller", "Mouse", "Keyboard") ~ "Click-based",
Input.device %in% c("Touch screen", "Trackpad") ~ "Tap-based"),
Inputdevice.new  = factor(Inputdevice.new , levels=c("Click-based", "Tap-based")))
survey %>% count(Inputdevice.new)


### deal with Age
##survey <- survey %>%
##mutate(Age.new = case_when(
##Age %in% c("18", "19")~ "18 ~ 19",
##Age %in% c("20", "21", "22", "23") ~ "20 ~ 23",
##Age %in% c("24", "25", "27", "29", "30")~ "24 ~ 30"),
##Age.new  = factor(Age.new , levels=c("18 ~ 19", "20 ~ 23", "24 ~ 30")))
##survey %>% count(Age.new)

### deal with Fatigue.level
survey <- survey %>%
mutate(Fatigue.new = case_when(
Fatigue.level %in% c("Extremely fatigued", "Very fatigued")~ "H.Fatigue",
Fatigue.level %in% c("Moderately fatigued") ~ "M.Fatigue",
Fatigue.level %in% c("Not fatigued at all", "Slightly Fatigued")~ "L.Fatigue"),
Fatigue.new  = factor(Fatigue.new , levels=c("H.Fatigue", "M.Fatigue", "L.Fatigue")))
survey %>% count(Fatigue.new)

### deal with Noise.level
survey <- survey %>%
mutate(Noise.new = case_when(
Noise.level %in% c("7", "8", "9")~ "H.Noise",
Noise.level %in% c("4", "5", "6") ~ "M.Noise",
Noise.level %in% c("1", "2", "3")~ "L.Noise"),
Noise.new  = factor(Noise.new , levels=c("H.Noise", "M.Noise", "L.Noise")))
survey %>% count(Noise.new)

### deal with Primary.hand
survey <- survey %>%
mutate(RightHand.new = case_when(
Primary.hand == "Right hand"~ "Y", TRUE ~ "N"), ### TRUE here means the rest of the levels
RightHand.new = factor(RightHand.new, levels=c("Y", "N")))
survey %>% count(RightHand.new)

### deal with Visual.acuity (combine poor with very poor, as only 1 element in "very poor")
survey <- survey %>%
mutate(Visual.new = case_when(
Visual.acuity %in% c("Very Poor", "Poor")~ "Poor",
Visual.acuity %in% c("Excellent")~ "Excellent",
Visual.acuity %in% c("Good")~ "Good",
Visual.acuity %in% c("Average")~ "Average",),
Visual.new = factor(Visual.new, levels=c("Excellent", "Good", "Average", "Poor")))
survey %>% count(Visual.new)

### deal with Temp.level (combine very cold with cold, very warm with warm)
survey <- survey %>%
mutate(Temp.new = case_when(
Temp.level %in% c("Very Warm", "Warm")~ "Warm",
Temp.level %in% c("Very Cold", "Cold")~ "Cold",
Temp.level %in% c("Neutral")~ "Neutral"),
Temp.new = factor(Temp.new, levels=c("Warm", "Cold", "Neutral")))
survey %>% count(Temp.new)

### deal with Cautious.level(combine Extremely cautious with very cautious, Not cautious at all with slightly cautious)
survey <- survey %>%
mutate(Cautious.new = case_when(
Cautious.level %in% c("Extremely cautious", "Very cautious")~ "H.cautious",
Cautious.level %in% c("Not cautious at all", "Slightly cautious")~ "L.cautious",
Cautious.level %in% c("Moderately cautious")~ "M.cautious"),
Cautious.new = factor(Cautious.new, levels=c("H.cautious", "L.cautious", "M.cautious")))
survey %>% count(Cautious.new)

### deal with Device.OS
survey <- survey %>%
  mutate(
    is_apple = ifelse(grepl("macOS|iOS|Apple|iPhone|iPad", Device.OS), "Apple", "Non-Apple"),
    is_mobile = ifelse(grepl("Smartphone|Tablet|iPhone|iPad", Device.OS), "Mobile", "Non-Mobile")
  )
survey %>% count(is_mobile)
survey %>% count(is_apple)

### Remove Alcohol
survey <- survey %>% select(-Alcohol.intake) 
survey 
```


### data exploration and summary


### data exploration and summary

```{r}
hist(survey$Reaction.time, main = "Histogram of Reaction Times", xlab = "Reaction Time (ms)")
```


```{r}
# Correlation heatmap for numerical variables
numerical_data <- survey %>% select(where(is.numeric))
corr_matrix <- cor(numerical_data)
corrplot(corr_matrix, method = "circle")

num_vars <- sapply(survey, is.numeric)
corr_data <- cor(survey[, num_vars], use = "complete.obs")
melted_corr <- melt(corr_data)
ggplot(melted_corr, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1)) +
  labs(title = "Correlation Heatmap", x = "", y = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
### For numerical variables

# Scatter plot for numerical data relationships
ggplot(survey, aes(x = Age, y = Reaction.time)) +
  geom_point() +
  labs(title = "Scatter plot of Age vs. Reaction Time", x = "Age", y = "Reaction Time")

# Scatter plot: Reaction vs. Average Sleep Time
ggplot(survey, aes(x = Avg.sleep.time, y = survey$Reaction.time)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Reaction vs. Average Sleep Time", x = "Average Sleep Time (hours)", y = "Reaction (ms)")
g = lm(Reaction.time~ Avg.sleep.time, data = survey)
g2 = lm(Reaction.time ~ factor(Avg.sleep.time), data = survey)
anova(g, g2) #perform lack of fit test here Because the p-value > 0.05, we fail to reject H0. We conclude the SLR g provide an adequate fit for the data.

# Avg.hours.exercise
ggplot(survey, aes(x = Avg.hours.exercise, y = survey$Reaction.time)) +
  geom_point(color = "blue", alpha = 0.6) +
  labs(title = "Reaction vs. Average Sleep Time", x = "Average Sleep Time (hours)", y = "Reaction (ms)")


# Awake.hours
ggplot(survey, aes(x = Awake.hours, y = survey$Reaction.time)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Reaction vs. Average Sleep Time", x = "Average Sleep Time (hours)", y = "Reaction (ms)")


# last.night.sleep.time
ggplot(survey, aes(x = last.night.sleep.time, y = survey$Reaction.time)) +
  geom_point(color = "blue", alpha = 0.6) +
  labs(title = "Reaction vs. Average Sleep Time", x = "Average Sleep Time (hours)", y = "Reaction (ms)")
```
```{r}
# For catogorical variables:

#The relation between CLass and Age
boxplot(Age ~ Class, data=survey, main="Age by class", xlab="Class", ylab="Age")


# Boxplot: Reaction by is_mobile"
ggplot(survey, aes(x = is_mobile, y = survey$Reaction.time, fill = is_mobile)) +
  geom_boxplot() +
  labs(title = "Reaction Time by is_mobile",
       x = "Input is_mobile",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by is_apple"
ggplot(survey, aes(x = is_apple, y = survey$Reaction.time, fill = is_apple)) +
  geom_boxplot() +
  labs(title = "Reaction Time by is_apple",
       x = "Input is_apple",
       y = "Reaction Time (ms)") +
  theme_minimal()


# Boxplot: Reaction by Cautious.new"
ggplot(survey, aes(x = Cautious.new, y = survey$Reaction.time, fill = Cautious.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Cautious.new",
       x = "Input Cautious.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Temp.new"
ggplot(survey, aes(x = Temp.new, y = survey$Reaction.time, fill = Temp.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Temp.new",
       x = "Input Temp.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Visual.new"
ggplot(survey, aes(x = Visual.new, y = survey$Reaction.time, fill = Visual.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Visual.new",
       x = "Input Visual.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by RightHand.new"
ggplot(survey, aes(x = RightHand.new, y = survey$Reaction.time, fill = RightHand.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by RightHand.new",
       x = "Input RightHand.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Noise.new"
ggplot(survey, aes(x = Noise.new, y = survey$Reaction.time, fill = Noise.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Noise.new",
       x = "Input Noise.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Fatigue.new"
ggplot(survey, aes(x = Fatigue.new, y = survey$Reaction.time, fill = Fatigue.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Fatigue.new",
       x = "Input Fatigue.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Inputdevice.new"
ggplot(survey, aes(x = Inputdevice.new, y = survey$Reaction.time, fill = Inputdevice.new)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Inputdevice.new",
       x = "Input Inputdevice.new",
       y = "Reaction Time (ms)") +
  theme_minimal()

ggplot(survey, aes(x = Inputdevice.new, y = survey$Reaction.time, fill = Inputdevice.new)) +
  geom_violin(trim = FALSE) +
  geom_boxplot(width = 0.1, fill = "white") +  # Adding a narrow boxplot inside for more detail
  labs(title = "Reaction Time by Input Device",
       x = "Input Device",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by WiFi.stable"
ggplot(survey, aes(x = WiFi.stable, y = survey$Reaction.time, fill = WiFi.stable)) +
  geom_boxplot() +
  labs(title = "Reaction Time by WiFi.stable",
       x = "Input WiFi.stable",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Use.primary.hand"
ggplot(survey, aes(x = Use.primary.hand, y = survey$Reaction.time, fill = Use.primary.hand)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Use.primary.hand",
       x = "Input Use.primary.hand",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Caffein.intake"
ggplot(survey, aes(x = Caffein.intake, y = survey$Reaction.time, fill = Caffein.intake)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Caffein.intake",
       x = "Input Caffein.intake",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Sport.freq"
ggplot(survey, aes(x = Sport.freq, y = survey$Reaction.time, fill = Sport.freq)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Sport.freq",
       x = "Input Sport.freq",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Game.freq"
ggplot(survey, aes(x = Game.freq, y = survey$Reaction.time, fill = Game.freq)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Game.freq",
       x = "Input Game.freq",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Distraction"
ggplot(survey, aes(x = Distraction, y = survey$Reaction.time, fill = Distraction)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Distraction",
       x = "Input Distraction",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Stress.level"
ggplot(survey, aes(x = Stress.level, y = survey$Reaction.time, fill = Stress.level)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Stress.level",
       x = "Input Stress.level",
       y = "Reaction Time (ms)") +
  theme_minimal()

# Boxplot: Reaction by Class"
ggplot(survey, aes(x = Class, y = survey$Reaction.time, fill = Class)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Class",
       x = "Input Class",
       y = "Reaction Time (ms)") +
  theme_minimal()
```

From boxplot, seems "visual" and "input device" has more obvious linear relation with reaction time.

## deal with dataset


```{r}
survey_new <- survey[, c("Reaction.time", "Class", "Avg.sleep.time", "last.night.sleep.time", "Awake.hours", "Stress.level", "Distraction", "Noise.new", "Temp.new", "Game.freq", "Sport.freq", "Avg.hours.exercise", "Caffein.intake",  "is_mobile", "is_apple", "Age", "Cautious.new", "Inputdevice.new", "Visual.new", "RightHand.new", "Fatigue.new", "WiFi.stable", "Use.primary.hand")]

survey_new
```



### Non-parametric part (not sure..)

### There are 5 numerical variables in our dataset, I want to visually determine their relationship with reaction time 

### Avg.sleep.time : linear fit 
```{r}
plot(Reaction.time~Avg.sleep.time, data=survey_new,col="gray", cex=0.5)
lines(smooth.spline(survey_new$Avg.sleep.time,survey_new$Reaction.time), lwd=1.5, col="red")
```
### Age: linear fit
```{r}
plot(Reaction.time~Age, data=survey_new,col="gray", cex=0.5)
lines(smooth.spline(survey_new$Age,survey_new$Reaction.time), lwd=1.5, col="red")
```

### last.night.sleep.time : linear fit 
```{r}
plot(Reaction.time~last.night.sleep.time, data=survey_new,col="gray", cex=0.5)
lines(smooth.spline(survey_new$last.night.sleep.time,survey_new$Reaction.time), lwd=1.5, col="red")
```
### awake hours : linear fit 
```{r}
plot(Reaction.time~Awake.hours, data=survey_new,col="gray", cex=0.5)
lines(smooth.spline(survey_new$Awake.hours,survey_new$Reaction.time), lwd=1.5, col="red")
```
### Avg.hours.exercise
```{r}
plot(Reaction.time~Avg.hours.exercise, data=survey_new,col="gray", cex=0.5)
lines(smooth.spline(survey_new$Avg.hours.exercise,survey_new$Reaction.time), lwd=1.5, col="red")
```
## check if linear regression is plausible for Avg.hours.exercise.
```{r}
summary(survey_new$Reaction.time)
plot(Reaction.time~Avg.hours.exercise, data=survey_new,col="gray", cex=0.5, ylim=c(150, 520))
f=loess(Reaction.time~Avg.hours.exercise, data=survey_new)
pred = predict(f, se=T)
i = order(survey_new$Avg.hours.exercise)
lines(f$x[i],f$fitted[i], lwd=1.5, col="red") #The line for the fit
lines(f$x[i],f$fitted[i]-qt(0.975, pred$df)*pred$se.fit[i], lty=2) #Lower bound
lines(f$x[i],f$fitted[i]+qt(0.975, pred$df)*pred$se.fit[i], lty=2) #Upper bound
#abline(lm(gamble~income, data=teengamb),lwd=1.5,col="blue",lty = "dotted") 


library(tidyverse)
survey_new %>%
ggplot(aes(x=Avg.hours.exercise, y = Reaction.time))+
geom_point(alpha=0.5)+
geom_smooth(method="loess", se = TRUE,color="red")+
geom_smooth(method="lm", formula = y ~ x,linetype="dotted",
color="blue", se=FALSE)

```
From the above output, we can say that a linear fit is plausible

Thus, for these numerical variable, linear regression is plausible.

## Colinearity check

```{r}
corr_data <- cor(survey[, num_vars], use = "complete.obs")
corr_data
```
There's no strong colinearity


### variable selection
### numerical variable selection

```{r}
#AB_test for Inputdevice.new

#H0：The reaction time of Click-based and Tap-based are not significant different.
#H1：The reaction time of Click-based and Tap-based are significant different.

# Assuming the correct column name is 'Inputdevice.new' and the value is 'Click-based'
click_based_data <- survey$Reaction.time[survey$Inputdevice.new == 'Click-based']
tap_based_data <- survey$Reaction.time[survey$Inputdevice.new == 'Tap-based']

shapiro_test_1 <- shapiro.test(click_based_data)
print(shapiro_test_1)
# p-value = 0.0006649 < 0.05 the mobile_data is not normal
shapiro_test_2 <- shapiro.test(tap_based_data)
print(shapiro_test_2)
# p-value = 1.08e-06 < 0.05 the mobile_data is not normal

# We use Mann-Whitney U test
mw_test_result <- wilcox.test(click_based_data, tap_based_data, alternative = "two.sided")
print(mw_test_result)
# p-value = 0.002503 < 0.05, the reaction time of Mobile and Non-Mobile are significant different.
```


```{r}
#g = lm(Reaction.time ~ ., data=survey_new)
g_num = lm(Reaction.time ~ Age + Avg.sleep.time + last.night.sleep.time + Awake.hours + Avg.hours.exercise, data=survey_new)
#summary(g)
summary(g_num)

```
For numerical variables, Age is significant.


One of Our research interest: explore the relationship between Age & Inputdevice & Reaction Time

### reference level
```{r}
contrasts(survey_new$Inputdevice.new)
```

We treat Click-based as our reference level 


### Model 1.1 the simplest model1 - Coincident regression line
```{r}
library(ggplot2)
library(tidyverse)
library(ggtext)
mod.1 <- lm(Reaction.time ~ Age, data = survey_new)
summary(mod.1)
p1.1 <- ggplot(survey_new, aes(Age, Reaction.time))+
  geom_point(alpha=0.5)+
  geom_smooth(method="lm", formula = y~x, se=FALSE, color="lightblue")+
  geom_smooth(method="lm", formula = y~x, se=FALSE, color="red", linetype="dotted")+
  theme(plot.title = element_markdown(hjust = 0.5))
p1.1


```



## Model 1.2 the simplest model - Two-mean model
```{r}
mod.2 <- lm(Reaction.time ~ Inputdevice.new, data = survey_new)
summary(mod.2)
p1.2 <- ggplot(survey_new, aes(Inputdevice.new, Reaction.time))+
  geom_point(alpha=0.3)+
  geom_point(aes(x="Click-based",y=247.84 ),alpha=0.1,
  colour='red', size=3)+
  geom_point(aes(x="Tap-based",y=247.84+27.59),alpha=0.1,
  colour="lightblue", size=3)+
  geom_hline(yintercept = 247.84, color="red")+
  geom_hline(yintercept = 247.84+27.59, color="lightblue")
p1.2
```

# Model 2 – Parallel regression lines (Additive Model)

```{r}
mod2 <- lm(Reaction.time ~ Age + Inputdevice.new, data = survey_new)
summary(mod2)
library(moderndive)
p2 <- ggplot(survey_new, aes(Age, Reaction.time, color=Inputdevice.new, linetype=Inputdevice.new))+
geom_point(alpha=0.3)+
geom_parallel_slopes(se=FALSE, fullrange=TRUE)
p2

```


### Model 3 – Regresslin lines with equal intercept but different slopes (?有点怪，为啥那俩线这么高，需要double check下)
```{r}
mean.Reactiontime = mean(survey_new$Reaction.time)
p3 <- ggplot(survey_new, aes(Age, Reaction.time, color=Inputdevice.new))+
  geom_point(alpha=0.3)+
  geom_smooth(method="glm", formula = y~x-1,
  position = position_nudge(y = mean.Reactiontime),
  se=FALSE, fullrange=TRUE)
p3

```


### Model 4 – Unrelated regression lines (Interaction Model)
```{r}
mod4 <- lm(Reaction.time ~ Age*Inputdevice.new, data = survey_new)
summary(mod4)
p4 <- ggplot(survey_new, aes(Age, Reaction.time, color=Inputdevice.new))+
  geom_point(alpha=0.3)+
  geom_smooth(method="lm", formula = y~x, se=FALSE, fullrange=TRUE)
p4

contrasts(survey_new$Inputdevice.new)
```
H0: beta_interaction = 0, Ha: beta_interaction != 0. As p-value = 0.5471 > 0.05, we fail to reject the null hypothesis. We conclude that the interaction term is not significant.


## Sequential anova table: 
```{r}
anova(lm(Reaction.time ~ Age*Inputdevice.new, data = survey_new))
```

## F-test for comparing two nested models:
```{r}
fit1 <- lm(Reaction.time ~ Age, data = survey_new)
fit2 <- lm(Reaction.time ~ Age + Inputdevice.new, data = survey_new)
anova(fit1, fit2)
```
 p-value = 0.00766 < 0.05, reject null hypothesis, we should use full model, thus additive model should be selected.
 
 
 
 
 
 
 
Question2: 

```{r}
full_model <- lm(Reaction.time ~ ., data = survey_new)
summary(full_model)
```

Variable selection

```{r}
library(leaps)
b=regsubsets(Reaction.time~., data = survey_new)
rs = summary(b)
rs$which
```
 
 
```{r}
n=dim(survey_new)[1]; msize = 2:9;
par(mfrow=c(2,2))
plot(msize, rs$adjr2, xlab="No. of Parameters", ylab = "Adjusted Rsquare");
plot(msize, rs$cp, xlab="No. of Parameters", ylab = "Mallow's Cp");

Aic = n*log(rs$rss/n) + 2*msize;
Bic = n*log(rs$rss/n) + msize*log(n);
plot(msize, Aic, xlab="No. of Parameters", ylab = "AIC");
plot(msize, Bic, xlab="No. of Parameters", ylab = "BIC");
```

```{r}
rs$which[which.min(Aic),]
select.var = colnames(rs$which)[rs$which[which.min(Aic),]]
select.var = select.var[-1]
# WiFi.stable+Visual.new+Inputdevice.new+Avg.hours.exercise+ Sport.freq+ Temp.new+Stress.level+Class
myfit = lm(Reaction.time ~  WiFi.stable+Visual.new+Inputdevice.new+Avg.hours.exercise+ Sport.freq+ Temp.new+Stress.level+Class, data=survey_new)
summary(myfit)
```

```{r}
anova(myfit, full_model)
```
p-value - 0.7301 > 0.05, we prefer myfit model.

```{r}
#culculate VIF，VIF > 5（or 10）means high collerality
vif_values1 <- vif(myfit)
print(vif_values1)
```
no collerality


Model Diagnostics
```{r}
plot(myfit)
```

```{r}
# BP test
#H0: hornoscedasticity
#H1: heteroscedasticity

library(lmtest)
bptest(myfit)
# p-value = 0.04997 < 0.05, fail to reject H0. , we conclude not constant variance.

# SW test:
# H0: Residuals follow normal distribution
# H1: Residuals don't follow normal distribution

shapiro.test(resid(myfit))
# p-value = 0.009174 < 0.05, reject H0. , we conclude residuals don't follow normal distribution

# DW test
# H0: residuals are uncorrelated
# H1: residuals are correlated

durbinWatsonTest(myfit)
# p-value = 0.87 > 0.05, fail to reject H0. , we conclude residuals are uncorrelated.
```



Address Non-Normality of Residuals:

Transformation of the Response Variable:
```{r}
library(MASS)
boxcox(myfit, plotit=T)
# Finding the optimal lambda using the boxcox function with the full model

# Assuming lambda = -0.5 is optimal
optimal_lambda <- -0.5
survey_new$Transformed_Reaction.time <- (survey_new$Reaction.time^optimal_lambda - 1) / optimal_lambda

transformed_myfit = lm(Transformed_Reaction.time ~  WiFi.stable+Visual.new+Inputdevice.new+Avg.hours.exercise+ Sport.freq+ Temp.new+Stress.level+Class, data=survey_new)

summary(transformed_myfit)


shapiro.test(resid(transformed_myfit))
# p-value = 0.4622 > 0.05, fail to reject H0. , we conclude residuals follow normal distribution


AIC(myfit)
AIC(transformed_myfit)

# p-value of transformed_reduced_model1 is greater than the p-value of reduced_model1, and AIC of transformed_reduced_model1 is less than AIC of reduced_model1, so transformed_reduced_model1 is better.
```



```{r}
plot(transformed_myfit)


# BP test
#H0: hornoscedasticity
#H1: heteroscedasticity

bptest(transformed_myfit)
# p-value = 0.1085 > 0.05, reject H0. , we conclude variance is constant.

# SW test:
# H0: Residuals follow normal distribution
# H1: Residuals don't follow normal distribution

shapiro.test(resid(transformed_myfit))
# p-value = 0.6634 > 0.05, reject H0. , we conclude residuals follow normal distribution

# DW test
# H0: residuals are uncorrelated
# H1: residuals are correlated

durbinWatsonTest(transformed_myfit)
# p-value = 0.54 > 0.05, fail to reject H0. , we conclude residuals are uncorrelated.
```

Leverages test
```{r}
library(car)
library(fdrtool)
library(faraway)


n = 141; p = 24
lev = influence(transformed_myfit)$hat
high_lev_points <- lev[lev > 2*p/n]# Identifying high leverage points
halfnorm(lev, 141, labs = row.names(survey_new), ylab="Leverages")


# Plotting leverage values
plot(lev, main="Leverage Values",ylim=c(0, max(c(lev, 2*p/n))))
abline(h=2*p/n, col="red") # Cutoff line
```
Outlier test

```{r}
n = 141
p = 24
df = 141-1-24
jack = rstudent(transformed_myfit)
qt(.05/(2*n), df) # Bonferoni correction, -3.680526

qt(.05/2, df) # Without Bonferoni correction, -1.980626

sort(abs(jack), decreasing = TRUE)[1:5]
#There is one outliers in this data set, since all studentized residual (in abs. values) are less than 3.679468


stu_res <- rstudent(transformed_myfit) # Studentized residuals
cutoff <- qt(0.05/(2*n), df) # Bonferroni adjustment for multiple comparisons
plot(stu_res, ylim=c(-6, 6), main="Studentized Residuals")
abline(h=c(-cutoff, cutoff), col="red")
```
Influential observations
```{r}
cook = cooks.distance(transformed_myfit)
max(cook)

halfnorm(cook, labs = row.names(survey_new), ylab = "cook's distance")
#According to the rule-of-thumb (CD ≥ 1), there are not influential observations. However, there is one observation that is too far from the rest.


CD <- cooks.distance(transformed_myfit)
plot(CD, main="Cook's Distance")
abline(h=1, col="red") # Common threshold for influential points
```
Lake of fit


```{r}

transformed_myfit = lm(Transformed_Reaction.time ~  WiFi.stable+Visual.new+Inputdevice.new+Avg.hours.exercise+ Sport.freq+ Temp.new+Stress.level+Class, data=survey_new)

transformed_myfit_factor <- lm(Transformed_Reaction.time ~  WiFi.stable+Visual.new+Inputdevice.new+Avg.hours.exercise + I(Avg.hours.exercise^2)+ Sport.freq+ Temp.new+Stress.level+Class, data=survey_new)

  
summary(transformed_myfit_factor)

anova(transformed_myfit,transformed_myfit_factor)
```

0.3666 > 0.05, so no lack of fit























 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 


